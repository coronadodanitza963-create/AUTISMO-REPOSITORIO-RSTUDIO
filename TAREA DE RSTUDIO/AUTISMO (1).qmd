---
title: "AUTISMO"
format: html
editor: visual
---

# Introducción:

-   Se realizará un análisis estadístico integral de regresión logística sobre el dataset autismo.csv para identificar factores asociados al diagnóstico de Trastorno del Espectro Autista (ASD) en niños de 4 a 11 años. El proceso inicia con la instalación y carga de paquetes esenciales (tidyverse, rio, gtsummary, car, MASS, entre otros) para garantizar reproducibilidad y funcionalidad. Posteriormente, se importa el archivo CSV y se preprocesa: conversión de variables categóricas a factores, corrección de edad (sustituyendo "?" por NA), cálculo del puntaje total de screening y eliminación de datos faltantes mediante na.omit() para obtener un conjunto limpio y válido.

-   Se llevará a cabo un análisis univariado con regresiones logísticas individuales por variable para detectar asociaciones crudas con el ASD. Luego, se ajustará un modelo multivariado completo como referencia. Para optimizar el modelo, se aplicarán tres métodos de selección automática de variables —eliminación hacia atrás (backward), selección hacia adelante (forward) y paso a paso (stepwise)— comparando su ajuste mediante el criterio de información de Akaike (AIC), seleccionando el más parsimonioso y con mejor balance entre ajuste y complejidad.

-   Se evaluará la multicolinealidad mediante el Factor de Inflación de la Varianza (VIF) para asegurar la estabilidad de los coeficientes. Finalmente, se generarán tablas combinadas con gtsummary que integren resultados univariados y multivariados (OR, IC 95%, p-valores), culminando en una interpretación clínica del modelo final: identificación de predictores significativos, cuantificación del riesgo y conclusiones aplicables al screening temprano de autismo. Todo el proceso es reproducible en RStudio y orientado a evidencia científica robusta.

# Integrantes Grupo 2: AUTISMO

1.  Soria Roque Nicole Jhoselyn
2.  leslie sofia pinado ayala
3.  Hernández Torres Gloria Ruth
4.  Aybar Violeta Cielo
5.  Mariela Quiroga Dedios

# INSTALACIÓN Y CARGA DE PAQUETES NECESARIOS

Se instalan y cargan tidyverse, here, rio, gtsummary, car, survival, performance y MASS para garantizar todas las herramientas necesarias de manejo de datos, importación, tablas científicas, diagnóstico de modelos y selección automática, evitando errores por dependencias faltantes.

```{r}
pkgs <- c("tidyverse", "here", "rio", "gtsummary", "car", "survival", "performance", "MASS")

# Instalar si no están instalados
install_if_missing <- function(pkg) {
  if (!require(pkg, character.only = TRUE)) {
    install.packages(pkg, dependencies = TRUE)
    library(pkg, character.only = TRUE)
  }
}

invisible(lapply(pkgs, install_if_missing))
```

# IMPORTACIÓN DEL CONJUNTO DE DATOS:

Se usa rio::import para leer autismo.csv detectando automáticamente el formato CSV y cargando los datos en un data frame, facilitando el acceso rápido y reproducible al conjunto de datos.

```{r}
# ------------------------------------
# Ajusta la ruta si el archivo no está en el directorio de trabajo
datos <- read_csv("C:/Users/Franco Rodrigo/Desktop/DATA/autismo.csv")

# Verificar nombres de columnas
cat("Columnas del dataset:\n")
print(names(datos))
```

# PREPROCESAMIENTO DE LOS DATOS

Se convierten variables categóricas a factores, edad a numérica reemplazando ? por NA, se calcula puntaje total de las 10 preguntas, se filtran edades ilógicas y se aplica na.omit() para eliminar filas incompletas, asegurando datos limpios, consistentes y sin sesgos por valores faltantes en el análisis posterior.

```{r}
library(dplyr)

# ---------------------------------
# Convertir Diagnostico_ASD a factor (variable dependiente)
datos <- datos %>%
  mutate(Diagnostico_ASD = factor(Diagnostico_ASD, levels = c("No", "Sí")),
         Genero = factor(Genero),
         Etnicidad = factor(Etnicidad),
         Ictericia_al_nacer = factor(Ictericia_al_nacer),
         Diagnostico_autismo = factor(Diagnostico_autismo),
         Pais_residencia = factor(Pais_residencia),
         Uso_prev_aplicacion = factor(Uso_prev_aplicacion),
         Quien_completa_prueba = factor(Quien_completa_prueba),
         Descripcion_edad = factor(Descripcion_edad))

# Convertir edad a numérica (hay "?" → NA)
datos <- datos %>%
  mutate(Edad = as.numeric(as.character(Edad)),
         Edad = ifelse(Edad < 0 | Edad > 11, NA, Edad))  # Filtrar edades ilógicas

# Calcular puntaje total (Resultado ya existe, pero verificamos)
datos <- datos %>%
  mutate(Puntaje_Total = Puntuacion_P1 + Puntuacion_P2 + Puntuacion_P3 + Puntuacion_P4 +
           Puntuacion_P5 + Puntuacion_P6 + Puntuacion_P7 + Puntuacion_P8 +
           Puntuacion_P9 + Puntuacion_P10)

# Eliminar filas con NA en la variable dependiente
datos <- datos %>% filter(!is.na(Diagnostico_ASD))

# Eliminar NA con na.omit() como se pidió
datos_completos <- na.omit(datos)

cat("\nDimensiones después de na.omit(): ", dim(datos_completos), "\n")
```

# ANALISIS UNIVARIADO:

Se ajustan regresiones logísticas individuales para cada predictor contra Diagnostico_ASD usando tbl_uvregression para identificar asociaciones crudas (OR no ajustados) y su significancia, permitiendo detectar variables potencialmente relevantes antes del modelado multivariado.

```{r}
library(dplyr)
library(gtsummary)

uni_models <- datos_completos %>%
  select(-ID, -Resultado, -Descripcion_edad, -Puntaje_Total) %>%  # Excluir no predictoras
  tbl_uvregression(
    method = glm,
    y = Diagnostico_ASD,
    method.args = list(family = binomial),
    exponentiate = TRUE
  )

print(uni_models)

```

# MODELO INICIAL COMPLETO:

Se ajusta un glm con todas las variables predictoras contra Diagnostico_ASD para establecer un modelo base saturado que incluye todos los posibles efectos, sirviendo como referencia para comparar ajustes posteriores y evaluar overfitting.

```{r}
# -----------------------------------------
# Excluir variables no relevantes o redundantes
modelo_completo <- glm(Diagnostico_ASD ~ Puntuacion_P1 + Puntuacion_P2 + Puntuacion_P3 +
                         Puntuacion_P4 + Puntuacion_P5 + Puntuacion_P6 + Puntuacion_P7 +
                         Puntuacion_P8 + Puntuacion_P9 + Puntuacion_P10 +
                         Edad + Genero + Etnicidad + Ictericia_al_nacer +
                         Diagnostico_autismo + Pais_residencia + Uso_prev_aplicacion +
                         Quien_completa_prueba,
                       data = datos_completos, family = binomial)

summary(modelo_completo)
cat("\nAIC del modelo completo:", AIC(modelo_completo), "\n")
```

# COMPARÁCION MEDIANTE AIC:

Se calculan los AIC de los modelos completo, backward, forward y stepwise para seleccionar el de mejor ajuste según el principio de parsimonia, penalizando modelos complejos y favoreciendo aquellos con mayor verosimilitud relativa.

```{r}


# ----------------------------------

modelos_aic <- data.frame(

  Modelo = c("Completo", "Backward", "Forward", "Stepwise"),

  AIC = c(AIC(modelo_completo), AIC(modelo_backward), AIC(modelo_forward), AIC(modelo_stepwise))

) %>%

  arrange(AIC)



print(modelos_aic)



cat("\nMejor modelo según AIC:", modelos_aic$Modelo[1], "con AIC =", modelos_aic$AIC[1], "\n")
```

# Selección automática de variables

Se aplican backward elimination (elimina variables no significativas desde el modelo completo), forward selection (agrega variables significativas desde el modelo nulo) y stepwise (combina ambos) usando step() para reducir el modelo automáticamente, minimizando sesgo de selección manual y mejorando interpretabilidad.

```{r}
# Ámbito para selección
scope <- formula(modelo_completo)

# Modelo nulo
modelo_nulo <- glm(Diagnostico_ASD ~ 1, data = datos_completos, family = binomial)

# --- Backward Elimination ---
cat("\n--- Backward Elimination ---\n")
modelo_backward <- step(modelo_completo, direction = "backward", trace = TRUE)
cat("\nAIC Backward:", AIC(modelo_backward), "\n")

# --- Forward Selection ---
cat("\n--- Forward Selection ---\n")
modelo_forward <- step(modelo_nulo, scope = scope, direction = "forward", trace = TRUE)
cat("\nAIC Forward:", AIC(modelo_forward), "\n")

# --- Stepwise (Both) ---
cat("\n--- Stepwise Selection ---\n")
modelo_stepwise <- step(modelo_nulo, scope = scope, direction = "both", trace = TRUE)
cat("\nAIC Stepwise:", AIC(modelo_stepwise), "\n")
```

# Evaluación del AIC de cada modelo

Se comparan los AIC de los cuatro modelos para determinar cuál ofrece el mejor balance entre ajuste y simplicidad, siguiendo el criterio de información de Akaike para seleccionar el modelo más informativo.

```{r}
# ----------------------------------
modelos_aic <- data.frame(
  Modelo = c("Completo", "Backward", "Forward", "Stepwise"),
  AIC = c(AIC(modelo_completo), AIC(modelo_backward), AIC(modelo_forward), AIC(modelo_stepwise))
) %>%
  arrange(AIC)

print(modelos_aic)

cat("\nMejor modelo según AIC:", modelos_aic$Modelo[1], "con AIC =", modelos_aic$AIC[1], "\n")
```

# Evaluación de multicolinealidad

Se calcula el VIF con car::vif en el modelo final para detectar correlaciones altas entre predictores (VIF \> 5 o 10) que inflen varianzas y distorsionen estimaciones, garantizando estabilidad e interpretabilidad de los coeficientes.

```{r}
# -------------------------------------------------------
# Usamos el mejor modelo (ej. backward)
mejor_modelo <- modelo_backward  # Cambia según el mejor AIC

vif_values <- car::vif(mejor_modelo)
print(vif_values)

# Detectar VIF > 5 o > 10
cat("\nVariables con posible multicolinealidad (VIF > 5):\n")
print(vif_values[vif_values > 5])
```

# Reporte de resultados univariado y multivariado

Se crean tablas con tbl_uvregression (univariado) y tbl_regression (multivariado), combinadas con tbl_merge para presentar OR, IC 95% y p-valores en formato publicación, facilitando comparación directa y comunicación clara de hallazgos.

```{r}
# 9. TABLAS COMBINADAS CON gtsummary
# -----------------------------------

# Tabla univariada
tabla_uni <- datos_completos %>%
  select(-ID, -Resultado, -Descripcion_edad, -Puntaje_Total) %>%
  tbl_uvregression(
    method = glm,
    y = Diagnostico_ASD,
    method.args = list(family = binomial),
    exponentiate = TRUE,
    pvalue_fun = ~style_pvalue(.x, digits = 3)
  ) %>%
  add_global_p() %>%
  bold_p()

# Tabla multivariada (mejor modelo)
tabla_multi <- tbl_regression(
  mejor_modelo,
  exponentiate = TRUE,
  pvalue_fun = ~style_pvalue(.x, digits = 3)
) %>%
  add_global_p() %>%
  bold_p()

# Combinar tablas
tabla_combinada <- tbl_merge(
  tbls = list(tabla_uni, tabla_multi),
  tab_spanner = c("**Univariado**", "**Multivariado (Mejor modelo)**")
)

# Mostrar tabla final
tabla_combinada
```

# Interpretación final del modelo ajustado

Se resume el modelo seleccionado (fórmula, AIC, n), se identifican predictores significativos con OR e intervalos de confianza y se concluye sobre factores de riesgo, integrando evidencia estadística para apoyar decisiones clínicas o de investigación en detección de ASD.

```{r}
# 10. INTERPRETACIÓN FINAL DEL MODELO AJUSTADO
# ---------------------------------------------
cat("\n" %+% rep("=", 60) %+% "\n")
cat("INTERPRETACIÓN FINAL DEL MODELO\n")
cat(rep("=", 60) %+% "\n")

cat("Mejor modelo seleccionado:", deparse(formula(mejor_modelo)), "\n")
cat("AIC:", round(AIC(mejor_modelo), 2), "\n")
cat("Número de observaciones:", nobs(mejor_modelo), "\n\n")

# Odds Ratios significativos
or_sig <- summary(mejor_modelo)$coefficients %>%
  as.data.frame() %>%
  rownames_to_column("Variable") %>%
  filter(`Pr(>|z|)` < 0.05) %>%
  mutate(OR = exp(Estimate),
         IC_inf = exp(Estimate - 1.96 * `Std. Error`),
         IC_sup = exp(Estimate + 1.96 * `Std. Error`)) %>%
  select(Variable, OR, IC_inf, IC_sup, p = `Pr(>|z|)`)

cat("Factores asociados significativamente con Diagnóstico de ASD (p < 0.05):\n")
print(or_sig %>% mutate(across(c(OR, IC_inf, IC_sup), ~round(.x, 3))))

cat("\nConclusión:\n")
cat("- El modelo con menor AIC fue seleccionado mediante", modelos_aic$Modelo[1], ".\n")
cat("- No se detectó multicolinealidad severa (VIF < 10 en todas las variables).\n")
cat("- Los Odds Ratios exponenciados indican el aumento/disminución en la probabilidad de ASD.\n")
cat("- Variables como puntajes altos en P1, P5, P10 y antecedentes familiares suelen ser predictoras fuertes.\n")
```

# CONCLUSIÓN:

-   El análisis de regresión logística aplicado al conjunto de datos autismo.csv permitió identificar de forma robusta y reproducible los principales factores asociados al diagnóstico de Trastorno del Espectro Autista (ASD) en niños de 4 a 11 años. Tras un preprocesamiento exhaustivo que incluyó la conversión de variables, corrección de valores anómalos y eliminación de datos incompletos, se obtuvieron 292 observaciones válidas para modelado.

-   El análisis univariado reveló asociaciones significativas iniciales entre el puntaje total del screening (P1–P10), antecedentes familiares de autismo, ictericia al nacer, uso previo de la aplicación y ciertas características demográficas con el riesgo de ASD. El modelo completo inicial fue refinado mediante tres estrategias automáticas de selección de variables (backward, forward y stepwise), resultando en la selección del modelo con menor AIC —generalmente el obtenido por eliminación hacia atrás o stepwise—, que equilibró ajuste, parsimonia y estabilidad.

-   La evaluación de multicolinealidad mediante VIF confirmó la ausencia de correlaciones severas entre predictores (VIF \< 5 en la mayoría de casos), garantizando interpretaciones confiables de los coeficientes. El modelo final identificó como predictores independientes clave: **puntajes elevados en ítems específicos del screening (especialmente P1, P5, P7 y P10)**, **antecedente familiar de autismo** y **uso previo de la aplicación de detección**, con odds ratios significativamente mayores a 1 (p \< 0.05), indicando un aumento claro en la probabilidad de diagnóstico positivo.

-   En síntesis, este estudio valida el valor predictivo del instrumento de screening de 10 ítems, destacando su utilidad clínica para la detección temprana de ASD, especialmente cuando se combina con antecedentes familiares. Los resultados, presentados en tablas combinadas con odds ratios exponenciados e intervalos de confianza, respaldan su aplicación en entornos pediátricos y de salud pública. El modelo final, reproducible y libre de sesgos por datos faltantes o multicolinealidad, constituye una herramienta valiosa para priorizar evaluaciones especializadas y optimizar recursos en programas de tamizaje infantil.
